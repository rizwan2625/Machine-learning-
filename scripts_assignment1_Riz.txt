################################################  ASSIGNMENT 1  ################################################

# PRELIMINARY ANALYSES 


# Import the dataset
setwd("C:/Users/sergi/Desktop/Riz") # to set your working directory
lymphography <- read.csv("C:/Users/sergi/Desktop/Riz/lymphography.csv", header=FALSE)
View(lymphography)
Data <- lymphography
class(Data) # to check that it is a data.frame
dim(Data) # to see the dimensions of the data set
summary(Data) # to get an overview of the values for your variables

# To tranform the data into factors
Data$V1<-as.factor(Data$V1)
Data$V2<-as.factor(Data$V2)
Data$V3<-as.factor(Data$V3)
Data$V4<-as.factor(Data$V4)
Data$V5<-as.factor(Data$V5)
Data$V6<-as.factor(Data$V6)
Data$V7<-as.factor(Data$V7)
Data$V8<-as.factor(Data$V8)
Data$V9<-as.factor(Data$V9)
Data$V10<-as.factor(Data$V10)
Data$V11<-as.factor(Data$V11)
Data$V12<-as.factor(Data$V12)
Data$V13<-as.factor(Data$V13)
Data$V14<-as.factor(Data$V14)
Data$V15<-as.factor(Data$V15)
Data$V16<-as.factor(Data$V16)
Data$V17<-as.factor(Data$V17)
Data$V18<-as.factor(Data$V18)
Data$V19<-as.factor(Data$V19)

# Open some of the packages that will be needed
library(mlr)
library(ggplot2)
library(GGally)


# Create a new task
task1 = makeClassifTask(id = "lymphography", data = Data, target = "V1") # class variable: "Condition"
task1 # to inspect the task
str(getTaskData(task1)) # to access the underlying data
getTaskFeatureNames(task1) # to inspect the feature names

# Exploratory analysis
ggpairs(Data) # This is not useful in my case... I've too many variables!!
ggpairs(Data[,7:10]) # to get the plots for a subset

# Learners
lrns_mytask<-listLearners(task1) # to get the list of learners available for your task
lrns_mytask[1:5, ]
lrns_mytask[6:10, ]

# Selected models:
# classif.IBk       k-Nearest Neighbours         ibk # Non-prob
# classif.J48         J48 Decision Trees         j48 # Non-prob
# classif.multinom Multinomial regression        multinom # Prob
# classif.naiveBayes                  Naive Bayes     nbayes# Prob

# Performance measures
listMeasures(task1) # to get the list of performance measures available for your task
accTrainMean<-setAggregation(acc, train.mean) # to define performance measures for the train set
accTrainMean
mmceTrainMean<-setAggregation(mmce, train.mean)
mmceTrainMean
kappaTrainMean<-setAggregation(kappa, train.mean)
kappaTrainMean
multiclass.brierTrainMean<-setAggregation(multiclass.brier, train.mean)
multiclass.brierTrainMean

accTrainSD<-setAggregation(acc, train.sd) # to define performance measures for the train set
accTrainSD
mmceTrainSD<-setAggregation(mmce, train.sd)
mmceTrainSD
kappaTrainSD<-setAggregation(kappa, train.sd)
kappaTrainSD
multiclass.brierTrainSD<-setAggregation(multiclass.brier, train.sd)
multiclass.brierTrainSD

accTestSD<-setAggregation(acc, test.sd) # to define performance measures for the train set
accTestSD
mmceTestSD<-setAggregation(mmce, test.sd)
mmceTestSD
kappaTestSD<-setAggregation(kappa, test.sd)
kappaTestSD
multiclass.brierTestSD<-setAggregation(multiclass.brier, test.sd)
multiclass.brierTestSD

# Resampling strategies
holdout<-makeResampleDesc("Holdout", predict = "both", stratify = TRUE) # Resampling using holdout approach
holdout

#########################
# EXPLORARION OF MODELS #
#########################

#################### k-NN ####################

lrn.knn <- makeLearner("classif.IBk") # to make the learner
getParamSet(lrn.knn) # to get a description of all possible settings (we won't change any of these...)
mod.knn <- train(lrn.knn, task1) # to train the model
mod.knn
getLearnerModel(mod.knn) # to access the underlying model
pred.knn <- predict(mod.knn, task1) # to predict the output of the model on training data
head(as.data.frame(pred.knn)) # to get predicted vs. true values
tail(as.data.frame(pred.knn))
calculateConfusionMatrix(pred.knn) # to compute the confusion matrix
performance(pred.knn, measures = list(acc, mmce, kappa)) # to estimate the performance measures

## Resampling
hd.knn<-resample(lrn.knn, task1, holdout, measures = list(acc, mmce, kappa, accTestSD, mmceTestSD, kappaTestSD, accTrainMean, mmceTrainMean, kappaTrainMean, accTrainSD, mmceTrainSD, kappaTrainSD)) # holdout
hd.knn$aggr
pred.hd.knn<-getRRPredictions(hd.knn) # to get the predictions obtained with the resampling
pred.hd.knn

#################### J48 ####################

lrn.j48 <- makeLearner("classif.J48") # to make the learner
getParamSet(lrn.j48) # to get a description of all possible settings (we won't change any of these...)
mod.j48 <- train(lrn.j48, task1) # to train the model
mod.j48
getLearnerModel(mod.j48) # to access the underlying model
pred.j48 <- predict(mod.j48, task1) # to predict the output of the model on training data
head(as.data.frame(pred.j48)) # to get predicted vs. true values
tail(as.data.frame(pred.j48))
calculateConfusionMatrix(pred.j48) # to compute the confusion matrix
performance(pred.j48, measures = list(acc, mmce, kappa)) # to estimate the performance measures

## Resampling
hd.j48<-resample(lrn.j48, task1, holdout, measures = list(acc, mmce, kappa, accTestSD, mmceTestSD, kappaTestSD, accTrainMean, mmceTrainMean, kappaTrainMean, accTrainSD, mmceTrainSD, kappaTrainSD)) # holdout
hd.j48$aggr
pred.hd.j48<-getRRPredictions(hd.j48) # to get the predictions obtained with the resampling
pred.hd.j48

#################### MULTINOMIAL REGRESSION ####################

lrn.mr <- makeLearner("classif.multinom", predict.type = "prob") # to make the learner; predict.type set to "prob"!!
getParamSet(lrn.mr) # to get a description of all possible settings (we won't change any of these...)
mod.mr <- train(lrn.mr, task1) # to train the model
mod.mr
getLearnerModel(mod.mr) # to access the underlying model
pred.mr <- predict(mod.mr, task1) # to predict the output of the model on training data
head(as.data.frame(pred.mr)) # to get predicted vs. true values
tail(as.data.frame(pred.mr))
calculateConfusionMatrix(pred.mr) # to compute the confusion matrix
performance(pred.mr, measures = list(acc, mmce, kappa, multiclass.brier)) # to estimate the performance measures

## Resampling ####
hd.mr<-resample(lrn.mr, task1, holdout, measures = list(acc, mmce, kappa, multiclass.brier, accTestSD, mmceTestSD, kappaTestSD, multiclass.brierTrainSD, accTrainMean, mmceTrainMean, kappaTrainMean, multiclass.brierTrainMean, accTrainSD, mmceTrainSD, kappaTrainSD, multiclass.brierTrainSD)) # holdout
hd.mr$aggr
pred.hd.mr<-getRRPredictions(hd.mr) # to get the predictions obtained with the resampling
pred.hd.mr

#################### NAÏVE BAYES ####################

lrn.nb <- makeLearner("classif.naiveBayes", predict.type = "prob") # to make the learner; predict.type set to "prob"!!
getParamSet(lrn.nb) # to get a description of all possible settings (we won't change any of these...)
mod.nb <- train(lrn.nb, task1) # to train the model
mod.nb
getLearnerModel(mod.nb) # to access the underlying model
pred.nb <- predict(mod.nb, task1) # to predict the output of the model on training data
head(as.data.frame(pred.nb)) # to get predicted vs. true values
tail(as.data.frame(pred.nb))
calculateConfusionMatrix(pred.nb) # to compute the confusion matrix
performance(pred.nb, measures = list(acc, mmce, kappa, multiclass.brier)) # to estimate the performance measures

## Resampling
hd.nb<-resample(lrn.nb, task1, holdout, measures = list(acc, mmce, kappa, multiclass.brier, accTestSD, mmceTestSD, kappaTestSD, multiclass.brierTrainSD, accTrainMean, mmceTrainMean, kappaTrainMean, multiclass.brierTrainMean, accTrainSD, mmceTrainSD, kappaTrainSD, multiclass.brierTrainSD)) # holdout
hd.nb$aggr
pred.hd.nb<-getRRPredictions(hd.nb) # to get the predictions obtained with the resampling
pred.hd.nb


